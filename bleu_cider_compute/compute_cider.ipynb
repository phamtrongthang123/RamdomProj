{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd073b831e701791890a3f59b0fe02180943739475b7622f56ac4dddfa4795d20b0",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ['A car show with people looking at cars at Becker Auto Body',\t'Car that is driving pass people and becker auto body',\t'A red muscle car with the license plate IDH 1969 drives past Becker Auto Body.',\t'Red car that has the letters SS on the front.',\t'Red car with a plate that says TDH1969 on it.']\n",
    "gt = [g.lower() for g in gt]\n",
    "pred = 'a car have letters becker auto body on the side side side' # 1.280712469652576\n",
    "pred = 'a car have letters becker letters becker auto body on the side side side' # 0.894960035508763\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: get ngram and frequency\n",
    "def precook(s, n=4, out=False):\n",
    "    words = s.split()\n",
    "    counts = defaultdict(int)\n",
    "    for k in range(1,n+1):\n",
    "        for i in range(len(words)-k+1):\n",
    "            ngram = tuple(words[i:i+k])\n",
    "            counts[ngram] += 1\n",
    "    return counts\n",
    "\n",
    "pred_ngram = precook(pred)\n",
    "gt_ngram = []\n",
    "for i, s in enumerate(gt):\n",
    "    gt_ngram.append(precook(s))\n",
    "\n",
    "# print(\"Prediction ngram: \\n%s\" %pred_nrgam)\n",
    "# print(\"Ground truth ngram: \\n%s\" % gt_ngram)"
   ]
  },
  {
   "source": [
    "The number of times an $n$ -gram $\\omega_{k}$ occurs in a reference sentence $s_{i j}$ is denoted by $h_{k}\\left(s_{i j}\\right)$ or $h_{k}\\left(c_{i}\\right)$ for the candidate sentence $c_{i} .$ We compute the TF-IDF weighting $g_{k}\\left(s_{i j}\\right)$ for each $n$ -gram $\\omega_{k}$ using:\n",
    "$$ \n",
    "g_{k}\\left(s_{i j}\\right)=\\frac{h_{k}\\left(s_{i j}\\right)}{\\sum_{\\omega_{l} \\in \\Omega} h_{l}\\left(s_{i j}\\right)} \\log \\left(\\frac{|I|}{\\sum_{I_{p} \\in I} \\min \\left(1, \\sum_{q} h_{k}\\left(s_{p q}\\right)\\right)}\\right)\n",
    "$$\n",
    "where $\\Omega$ is the vocabulary of all $n$ -grams and $I$ is the set of all images in the dataset. The first term measures the TF of each $n$ -gram $\\omega_{k}$, and the second term measures the rarity of $\\omega_{k}$ using its IDF. Intuitively, TF places higher weight on $n$ -grams that frequently occur in the reference sentence describing an image, while IDF reduces the weight of $n$ grams that commonly occur across all images in the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Compute Document Frequency\n",
    "document_frequency = defaultdict(float)\n",
    "\n",
    "# Change this depends on ground truth file\n",
    "gt_file = 'converted_TextCaps_0.1_val.json'\n",
    "with open(gt_file) as f:\n",
    "    gtv = json.load(f)['annotations']\n",
    "\n",
    "gtv_dic = defaultdict(list)\n",
    "for gti in gtv:\n",
    "    imgid = gti['image_id']\n",
    "    capt = gti['caption'].lower()\n",
    "    gtv_dic[imgid].append(precook(capt))\n",
    "\n",
    "\n",
    "images_len = float(len(gtv_dic.values()))\n",
    "# After have all ngrams, compute the document frequency\n",
    "for refs in gtv_dic.values():\n",
    "    for ngram in set([ngram for ref in refs for (ngram,count) in ref.items()]):\n",
    "        document_frequency[ngram] += 1\n",
    "\n",
    "# Note: Currently I tokenize it differently compare to the original method. \n",
    "# For example: 'I saw can that says \"g\" on it'. Currently we will consider '\"g\"' as a token. The original may consider '\"' as token or delete the '\"'. It more of engineering so I skipped this part. \n",
    "\n",
    "\n",
    "# If you use pickle coco-val-df, remember load as latin1 and images_len is 40504\n",
    "# tmp_path = 'coco-val-df.p'\n",
    "# with open(tmp_path,'rb') as f:\n",
    "#     document_frequency = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# images_len = float(40504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define h function\n",
    "def h_func(_ngram, wk):\n",
    "    return _ngram[wk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define g function\n",
    "def g_func(_ngram, wk):\n",
    "    h_ks = h_func(_ngram, wk)\n",
    "    sum_hls = 0 \n",
    "    for w, freq in _ngram.items():\n",
    "        sum_hls += freq\n",
    "    first_term = h_ks #/ sum_hls \n",
    "    second_term = np.log(images_len / max(1.0, document_frequency[wk]))\n",
    "    return float(first_term) * second_term\n",
    "\n"
   ]
  },
  {
   "source": [
    "Our CIDEr $_{n}$ score for $n$ -grams of length $n$ is computed using the average cosine similarity between the candidate sentence and the reference sentences, which accounts for both precision and recall:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{CIDEr}-\\mathrm{D}_{n}\\left(c_{i}, S_{i}\\right) &=\\frac{10}{m} \\sum_{j} e^{\\frac{-\\left(l\\left(c_{i}\\right)-l\\left(s_{i j}\\right)\\right)^{2}}{2 \\sigma^{2}}} * & \\frac{\\min \\left(\\boldsymbol{g}^{\\boldsymbol{n}}\\left(c_{i}\\right), \\boldsymbol{g}^{\\boldsymbol{n}}\\left(s_{i j}\\right)\\right) \\cdot \\boldsymbol{g}^{\\boldsymbol{n}}\\left(s_{i j}\\right)}{\\left\\|\\boldsymbol{g}^{\\boldsymbol{n}}\\left(c_{i}\\right)\\right\\|\\left\\|\\boldsymbol{g}^{\\boldsymbol{n}}\\left(s_{i j}\\right)\\right\\|}\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\boldsymbol{g}^{n}\\left(c_{i}\\right)$ is a vector formed by $g_{k}\\left(c_{i}\\right)$ corresponding to all $n$ -grams of length $n$ and $\\left\\|\\boldsymbol{g}^{n}\\left(c_{i}\\right)\\right\\|$ is the magnitude of the vector $\\boldsymbol{g}^{\\boldsymbol{n}}\\left(c_{i}\\right)$. Similarly for $\\boldsymbol{g}^{\\boldsymbol{n}}\\left(s_{i j}\\right)$.\n",
    "\n",
    "$l\\left(c_{i}\\right)$ and $l\\left(s_{i j}\\right)$ denote the lengths of candidate and reference sentences respectively. We use $\\sigma=6 .$ A factor of 10 is added to make the CIDEr-D scores numerically similar to other metrics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: define vector g function \n",
    "# I modified a bit because our ngram have all ngram len inside it \n",
    "def vector_g_func(_ngram, n =4):\n",
    "    gn_ = [defaultdict(float) for _ in range(n)] \n",
    "    norm_gn_ = [0 for _ in range(n)]\n",
    "    length = 0\n",
    "    for ng, freq in _ngram.items():\n",
    "        index_n = len(ng) - 1\n",
    "        gn_[index_n][ng] = g_func(_ngram, ng)\n",
    "        norm_gn_[index_n] += pow(gn_[index_n][ng], 2)\n",
    "        if index_n == 1:\n",
    "            length += freq\n",
    "    norm_gn_ = [np.sqrt(no) for no in norm_gn_]\n",
    "    return norm_gn_, gn_, length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: define CIDEr_n_j\n",
    "def cider_n_j(cand_vec, ref_vec, norm_c, norm_r, len_c, len_r, n=4):\n",
    "    delta = float(len_c - len_r)\n",
    "    res = [0 for _ in range(n)]\n",
    "    for ni in range(n):\n",
    "        for (ngram,count) in cand_vec[ni].items():\n",
    "            res[ni] += min(cand_vec[ni][ngram], ref_vec[ni][ngram]) * ref_vec[ni][ngram]\n",
    "        if (norm_c[ni] != 0) and (norm_r[ni] != 0):\n",
    "            res[ni] /= (norm_c[ni]*norm_r[ni])\n",
    "        sigma = 6.0\n",
    "        res[ni] *= np.e**(-(delta**2)/(2*sigma**2))\n",
    "    return res\n"
   ]
  },
  {
   "source": [
    "$$\n",
    "\\operatorname{CIDEr}-\\mathrm{D}\\left(c_{i}, S_{i}\\right)=\\sum_{n=1}^{N} w_{n} \\operatorname{CIDEr}-\\mathrm{D}_{n}\\left(c_{i}, S_{i}\\right)\n",
    "$$\n",
    "Empirically, we found that uniform weights $w_{n}=1 / N$ work the best. We use $N=4$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Define CIDEr\n",
    "def CIDEr(cand_ngram, refs_ngram):\n",
    "    norm_gn_c, gn_c, len_c = vector_g_func(cand_ngram)\n",
    "    score = np.array([0.0 for _ in range(4)])\n",
    "    for ref_ngram in refs_ngram:\n",
    "        norm_gn_r, gn_r, len_r = vector_g_func(ref_ngram)\n",
    "        score += cider_n_j(gn_c, gn_r, norm_gn_c, norm_gn_r, len_c, len_r)\n",
    "    score_avg = np.mean(score)\n",
    "    score_avg /= len(refs_ngram)\n",
    "    score_avg *= 10.0\n",
    "    return score_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.894960035508763"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "CIDEr(pred_ngram, gt_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}